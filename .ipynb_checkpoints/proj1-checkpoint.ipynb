{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from scipy.io import loadmat\n",
    "from numpy.linalg import det, inv\n",
    "from math import sqrt, pi\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import sys\n",
    "from scipy.stats import multivariate_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Accuracy = 0.97\n",
      "QDA Accuracy = 0.96\n"
     ]
    }
   ],
   "source": [
    "if sys.version_info.major == 2:\n",
    "    X,y,Xtest,ytest = pickle.load(open('sample.pickle','rb'))\n",
    "else:\n",
    "    X,y,Xtest,ytest = pickle.load(open('sample.pickle','rb'),encoding = 'latin1')\n",
    "\n",
    "def find_covariance(input_mat,mean,pool_cov_base): # function to find covariance for each class\n",
    "    first=input_mat-mean\n",
    "    second=first.transpose()\n",
    "    third=np.matmul(second,first)\n",
    "    fourth=((input_mat.size)/2)-1\n",
    "    pool_cov_base=pool_cov_base+fourth\n",
    "    final=third\n",
    "    return final,pool_cov_base\n",
    "def find_mean(input_mat):  # function to find mean for each class\n",
    "    input_mat=np.array(input_mat)\n",
    "    rows=(input_mat.size)/2\n",
    "    input_mat=np.reshape(input_mat,(int(rows),2))\n",
    "    mean=input_mat.mean(0)\n",
    "    mean=mean.flatten()\n",
    "    mean=np.reshape(mean,(1,2))\n",
    "    return input_mat,mean\n",
    "def find_pool_covariance(c1,c2,c3,c4,c5,pool_cov_base): # function to find pool variance\n",
    "    pool_cov=c1+c2+c3+c4+c5\n",
    "    pool_cov_base=Xtest.size/2\n",
    "    pool_cov_base=pool_cov_base-5\n",
    "    pool_cov=pool_cov/pool_cov_base\n",
    "    return pool_cov\n",
    "def find_qda_covariance(input_mat,mean,pool_cov_base): # function to find covariance for each class\n",
    "    first=input_mat-mean\n",
    "    second=first.transpose()\n",
    "    third=np.matmul(second,first)\n",
    "    fourth=((input_mat.size)/2)-1\n",
    "    pool_cov_base=pool_cov_base+fourth\n",
    "    final=third/fourth\n",
    "    return final,pool_cov_base\n",
    "def ldaLearn(X,y):\n",
    "    # Inputs\n",
    "    # X - a N x d matrix with each row corresponding to a training example\n",
    "    # y - a N x 1 column vector indicating the labels for each training example\n",
    "    #\n",
    "    # Outputs\n",
    "    # means - A d x k matrix containing learnt means for each of the k classes\n",
    "    # covmat - A single d x d learnt covariance matrix \n",
    "    \n",
    "    # IMPLEMENT THIS METHOD \n",
    "    index=0\n",
    "    mat1=[]\n",
    "    mat2=[]\n",
    "    mat3=[]\n",
    "    mat4=[]\n",
    "    mat5=[]\n",
    "    while(index<y.size):\n",
    "        if y[index] == 1:\n",
    "            mat1.append(X[index])\n",
    "        if y[index] == 2:\n",
    "            mat2.append(X[index])\n",
    "        if y[index] == 3:\n",
    "            mat3.append(X[index])\n",
    "        if y[index] == 4:\n",
    "            mat4.append(X[index])\n",
    "        if y[index] == 5:\n",
    "            mat5.append(X[index])\n",
    "        index=index+1\n",
    "    pool_cov_base=0;\n",
    "    mat1,mean1=find_mean(mat1)\n",
    "    cov1,pool_cov_base=find_covariance(mat1,mean1,pool_cov_base)\n",
    "    mat2,mean2=find_mean(mat2)\n",
    "    cov2,pool_cov_base=find_covariance(mat2,mean2,pool_cov_base)\n",
    "\n",
    "    mat3,mean3=find_mean(mat3)\n",
    "    cov3,pool_cov_base=find_covariance(mat3,mean3,pool_cov_base)\n",
    "\n",
    "    mat4,mean4=find_mean(mat4)\n",
    "    cov4,pool_cov_base=find_covariance(mat4,mean4,pool_cov_base)\n",
    "\n",
    "    mat5,mean5=find_mean(mat5)\n",
    "    cov5,pool_cov_base=find_covariance(mat5,mean5,pool_cov_base)\n",
    "\n",
    "    means=[]\n",
    "    means.append(mean1)\n",
    "    means.append(mean2)\n",
    "    means.append(mean3)\n",
    "    means.append(mean4)\n",
    "    means.append(mean5)\n",
    "    means=np.array(means)\n",
    "    means=np.asmatrix(means)\n",
    "    means=means.transpose()\n",
    "    total_class=5;\n",
    "    pool_cov_base=(X.size/2)-total_class;\n",
    "    covmat=find_pool_covariance(cov1,cov2,cov3,cov4,cov5,pool_cov_base)\n",
    "    return means,covmat\n",
    "def qdaLearn(X,y):\n",
    "    # Inputs\n",
    "    # X - a N x d matrix with each row corresponding to a training example\n",
    "    # y - a N x 1 column vector indicating the labels for each training example\n",
    "    #\n",
    "    # Outputs\n",
    "    # means - A d x k matrix containing learnt means for each of the k classes\n",
    "    # covmats - A list of k d x d learnt covariance matrices for each of the k classes\n",
    "    \n",
    "    # IMPLEMENT THIS METHOD\n",
    "    index=0\n",
    "    mat1=[]\n",
    "    mat2=[]\n",
    "    mat3=[]\n",
    "    mat4=[]\n",
    "    mat5=[]\n",
    "    while(index<y.size):\n",
    "        if y[index] == 1:\n",
    "            mat1.append(X[index])\n",
    "        if y[index] == 2:\n",
    "            mat2.append(X[index])\n",
    "        if y[index] == 3:\n",
    "            mat3.append(X[index])\n",
    "        if y[index] == 4:\n",
    "            mat4.append(X[index])\n",
    "        if y[index] == 5:\n",
    "            mat5.append(X[index])\n",
    "        index=index+1\n",
    "    pool_cov_base=0\n",
    "    mat1,mean1=find_mean(mat1)\n",
    "    cov1,pool_cov_base=find_qda_covariance(mat1,mean1,pool_cov_base)\n",
    "\n",
    "    mat2,mean2=find_mean(mat2)\n",
    "    cov2,pool_cov_base=find_qda_covariance(mat2,mean2,pool_cov_base)\n",
    "\n",
    "    mat3,mean3=find_mean(mat3)\n",
    "    cov3,pool_cov_base=find_qda_covariance(mat3,mean3,pool_cov_base)\n",
    "\n",
    "    mat4,mean4=find_mean(mat4)\n",
    "    cov4,pool_cov_base=find_qda_covariance(mat4,mean4,pool_cov_base)\n",
    "\n",
    "    mat5,mean5=find_mean(mat5)\n",
    "    cov5,pool_cov_base=find_qda_covariance(mat5,mean5,pool_cov_base)\n",
    "\n",
    "    means=[]\n",
    "    means.append(mean1)\n",
    "    means.append(mean2)\n",
    "    means.append(mean3)\n",
    "    means.append(mean4)\n",
    "    means.append(mean5)\n",
    "    means=np.array(means)\n",
    "    means=np.asmatrix(means)\n",
    "    means=means.transpose()\n",
    "    covmats=[]\n",
    "    covmats.append(cov1)\n",
    "    covmats.append(cov2)\n",
    "    covmats.append(cov3)\n",
    "    covmats.append(cov4)\n",
    "    covmats.append(cov5)\n",
    "    return means,covmats\n",
    "def ldaTest(means,covmat,Xtest,ytest):\n",
    "    # Inputs\n",
    "    # means, covmat - parameters of the LDA model\n",
    "    # Xtest - a N x d matrix with each row corresponding to a test example\n",
    "    # ytest - a N x 1 column vector indicating the labels for each test example\n",
    "    # Outputs\n",
    "    # acc - A scalar accuracy value\n",
    "    # ypred - N x 1 column vector indicating the predicted labels\n",
    "\n",
    "    # IMPLEMENT THIS METHOD\n",
    "    means=means.transpose()\n",
    "    index=0\n",
    "    index2=0\n",
    "    pdf=0;\n",
    "    classifier=0\n",
    "    total_wrong_labels=0;\n",
    "    ypred=[]\n",
    "    while(index<ytest.size):\n",
    "        x_i=Xtest[index]\n",
    "        index2=0\n",
    "        classifier=0\n",
    "        pdf=0\n",
    "        while(index2<(means.size)/2):\n",
    "            class_mean=means[index2]\n",
    "            class_mean=np.array(class_mean)\n",
    "            class_mean=class_mean.flatten()\n",
    "            pdf_i=multivariate_normal.pdf(x_i, class_mean, covmat)    \n",
    "            if(pdf_i>=pdf):\n",
    "                pdf=pdf_i\n",
    "                classifier=index2\n",
    "            index2=index2+1\n",
    "        label=classifier+1\n",
    "        if label != ytest[index]:\n",
    "            total_wrong_labels = total_wrong_labels+1\n",
    "        index=index+1\n",
    "        ypred.append(label)\n",
    "    acc=(ytest.size-total_wrong_labels)/ytest.size\n",
    "    ypred=np.array(ypred)\n",
    "    ypred=np.asmatrix(ypred)\n",
    "    ypred=ypred.transpose()\n",
    "    return acc,ypred\n",
    "\n",
    "def qdaTest(means,covmats,Xtest,ytest):\n",
    "    # Inputs\n",
    "    # means, covmats - parameters of the QDA model\n",
    "    # Xtest - a N x d matrix with each row corresponding to a test example\n",
    "    # ytest - a N x 1 column vector indicating the labels for each test example\n",
    "    # Outputs\n",
    "    # acc - A scalar accuracy value\n",
    "    # ypred - N x 1 column vector indicating the predicted labels\n",
    "\n",
    "    # IMPLEMENT THIS METHOD\n",
    "    means=means.transpose()\n",
    "    index=0\n",
    "    index2=0\n",
    "    pdf=0;\n",
    "    classifier=0\n",
    "    total_wrong_labels=0;\n",
    "    ypred=[]\n",
    "    while(index<ytest.size):\n",
    "        x_i=Xtest[index]\n",
    "        index2=0\n",
    "        classifier=0\n",
    "        pdf=0\n",
    "        while(index2<(means.size)/2):\n",
    "            class_mean=means[index2]\n",
    "            class_mean=np.array(class_mean)\n",
    "            class_mean=class_mean.flatten()\n",
    "            pdf_i=multivariate_normal.pdf(x_i, class_mean, covmats[index2])    \n",
    "            if(pdf_i>=pdf):\n",
    "                pdf=pdf_i\n",
    "                classifier=index2\n",
    "            index2=index2+1\n",
    "        label=classifier+1\n",
    "        if label != ytest[index]:\n",
    "            total_wrong_labels = total_wrong_labels+1\n",
    "        index=index+1\n",
    "        ypred.append(label)\n",
    "    acc=(ytest.size-total_wrong_labels)/ytest.size\n",
    "    ypred=np.array(ypred)\n",
    "    ypred=np.asmatrix(ypred)\n",
    "    ypred=ypred.transpose()\n",
    "    return acc,ypred\n",
    "# LDA\n",
    "means,covmat = ldaLearn(X,y)\n",
    "ldaacc,ldares = ldaTest(means,covmat,Xtest,ytest)\n",
    "print('LDA Accuracy = '+str(ldaacc))\n",
    "# QDA\n",
    "means,covmats = qdaLearn(X,y)\n",
    "qdaacc,qdares = qdaTest(means,covmats,Xtest,ytest)\n",
    "print('QDA Accuracy = '+str(qdaacc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# implementing LDA Learning\n",
    "if sys.version_info.major == 2:\n",
    "    X,y,Xtest,ytest = pickle.load(open('sample.pickle','rb'))\n",
    "else:\n",
    "    X,y,Xtest,ytest = pickle.load(open('sample.pickle','rb'),encoding = 'latin1')\n",
    "index=0\n",
    "mat1=[]\n",
    "mat2=[]\n",
    "mat3=[]\n",
    "mat4=[]\n",
    "mat5=[]\n",
    "while(index<y.size):\n",
    "    if y[index] == 1:\n",
    "        mat1.append(X[index])\n",
    "    if y[index] == 2:\n",
    "        mat2.append(X[index])\n",
    "    if y[index] == 3:\n",
    "        mat3.append(X[index])\n",
    "    if y[index] == 4:\n",
    "        mat4.append(X[index])\n",
    "    if y[index] == 5:\n",
    "        mat5.append(X[index])\n",
    "    index=index+1\n",
    "def find_covariance(input_mat,mean,pool_cov_base): # function to find covariance for each class\n",
    "    first=input_mat-mean\n",
    "    second=first.transpose()\n",
    "    third=np.matmul(second,first)\n",
    "    fourth=((input_mat.size)/2)-1\n",
    "    pool_cov_base=pool_cov_base+fourth\n",
    "    final=third\n",
    "    return final,pool_cov_base\n",
    "def find_mean(input_mat):  # function to find mean for each class\n",
    "    input_mat=np.array(input_mat)\n",
    "    rows=(input_mat.size)/2\n",
    "    input_mat=np.reshape(input_mat,(int(rows),2))\n",
    "    mean=input_mat.mean(0)\n",
    "    mean=mean.flatten()\n",
    "    mean=np.reshape(mean,(1,2))\n",
    "    return input_mat,mean\n",
    "def find_pool_covariance(c1,c2,c3,c4,c5,pool_cov_base): # function to find pool variance\n",
    "    pool_cov=c1+c2+c3+c4+c5\n",
    "    pool_cov_base=Xtest.size/2\n",
    "    pool_cov_base=pool_cov_base-5\n",
    "    pool_cov=pool_cov/pool_cov_base\n",
    "    return pool_cov\n",
    "pool_cov_base=0;\n",
    "mat1,mean1=find_mean(mat1)\n",
    "cov1,pool_cov_base=find_covariance(mat1,mean1,pool_cov_base)\n",
    "mat2,mean2=find_mean(mat2)\n",
    "cov2,pool_cov_base=find_covariance(mat2,mean2,pool_cov_base)\n",
    "\n",
    "mat3,mean3=find_mean(mat3)\n",
    "cov3,pool_cov_base=find_covariance(mat3,mean3,pool_cov_base)\n",
    "\n",
    "mat4,mean4=find_mean(mat4)\n",
    "cov4,pool_cov_base=find_covariance(mat4,mean4,pool_cov_base)\n",
    "\n",
    "mat5,mean5=find_mean(mat5)\n",
    "cov5,pool_cov_base=find_covariance(mat5,mean5,pool_cov_base)\n",
    "\n",
    "means=[]\n",
    "means.append(mean1)\n",
    "means.append(mean2)\n",
    "means.append(mean3)\n",
    "means.append(mean4)\n",
    "means.append(mean5)\n",
    "means=np.array(means)\n",
    "means=np.asmatrix(means)\n",
    "means=means.transpose()\n",
    "total_class=5;\n",
    "pool_cov_base=(X.size/2)-total_class;\n",
    "covmat=find_pool_covariance(cov1,cov2,cov3,cov4,cov5,pool_cov_base)\n",
    "#test lda\n",
    "means=means.transpose()\n",
    "index=0\n",
    "index2=0\n",
    "pdf=0;\n",
    "classifier=0\n",
    "total_wrong_labels=0;\n",
    "ypred=[]\n",
    "while(index<ytest.size):\n",
    "    x_i=Xtest[index]\n",
    "    index2=0\n",
    "    classifier=0\n",
    "    pdf=0\n",
    "    while(index2<(means.size)/2):\n",
    "        class_mean=means[index2]\n",
    "        class_mean=np.array(class_mean)\n",
    "        class_mean=class_mean.flatten()\n",
    "        pdf_i=multivariate_normal.pdf(x_i, class_mean, covmat)    \n",
    "        if(pdf_i>=pdf):\n",
    "            pdf=pdf_i\n",
    "            classifier=index2\n",
    "        index2=index2+1\n",
    "    label=classifier+1\n",
    "    if label != ytest[index]:\n",
    "        total_wrong_labels = total_wrong_labels+1\n",
    "    index=index+1\n",
    "    ypred.append(label)\n",
    "accuracy=(ytest.size-total_wrong_labels)/ytest.size\n",
    "ypred=np.array(ypred)\n",
    "ypred=np.asmatrix(ypred)\n",
    "ypred=ypred.transpose()\n",
    "            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 1.09113961, -0.1584732 ],\n",
      "       [-0.1584732 ,  1.66024746]]), array([[ 1.47887252,  0.0828507 ],\n",
      "       [ 0.0828507 ,  3.37775876]]), array([[ 2.25283733, -0.08148952],\n",
      "       [-0.08148952,  1.93070946]]), array([[ 1.7741846 , -0.40489726],\n",
      "       [-0.40489726,  2.07372154]]), array([[ 2.52050924, -0.05183432],\n",
      "       [-0.05183432,  1.67571127]])]\n"
     ]
    }
   ],
   "source": [
    "# implementing QDA Learning\n",
    "if sys.version_info.major == 2:\n",
    "    X,y,Xtest,ytest = pickle.load(open('sample.pickle','rb'))\n",
    "else:\n",
    "    X,y,Xtest,ytest = pickle.load(open('sample.pickle','rb'),encoding = 'latin1')\n",
    "index=0\n",
    "mat1=[]\n",
    "mat2=[]\n",
    "mat3=[]\n",
    "mat4=[]\n",
    "mat5=[]\n",
    "while(index<y.size):\n",
    "    if y[index] == 1:\n",
    "        mat1.append(X[index])\n",
    "    if y[index] == 2:\n",
    "        mat2.append(X[index])\n",
    "    if y[index] == 3:\n",
    "        mat3.append(X[index])\n",
    "    if y[index] == 4:\n",
    "        mat4.append(X[index])\n",
    "    if y[index] == 5:\n",
    "        mat5.append(X[index])\n",
    "    index=index+1\n",
    "def find_covariance(input_mat,mean,pool_cov_base): # function to find covariance for each class\n",
    "    first=input_mat-mean\n",
    "    second=first.transpose()\n",
    "    third=np.matmul(second,first)\n",
    "    fourth=((input_mat.size)/2)-1\n",
    "    pool_cov_base=pool_cov_base+fourth\n",
    "    final=third/fourth\n",
    "    return final,pool_cov_base\n",
    "def find_mean(input_mat):  # function to find mean for each class\n",
    "    input_mat=np.array(input_mat)\n",
    "    input_mat=input_mat.flatten()\n",
    "    rows=(input_mat.size)/2\n",
    "    input_mat=np.reshape(input_mat,(int(rows),2))\n",
    "    mean=input_mat.mean(0)\n",
    "    mean=mean.flatten()\n",
    "    mean=np.reshape(mean,(1,2))\n",
    "    return input_mat,mean\n",
    "mat1,mean1=find_mean(mat1)\n",
    "cov1,pool_cov_base=find_covariance(mat1,mean1,pool_cov_base)\n",
    "\n",
    "mat2,mean2=find_mean(mat2)\n",
    "cov2,pool_cov_base=find_covariance(mat2,mean2,pool_cov_base)\n",
    "\n",
    "mat3,mean3=find_mean(mat3)\n",
    "cov3,pool_cov_base=find_covariance(mat3,mean3,pool_cov_base)\n",
    "\n",
    "mat4,mean4=find_mean(mat4)\n",
    "cov4,pool_cov_base=find_covariance(mat4,mean4,pool_cov_base)\n",
    "\n",
    "mat5,mean5=find_mean(mat5)\n",
    "cov5,pool_cov_base=find_covariance(mat5,mean5,pool_cov_base)\n",
    "\n",
    "means=[]\n",
    "means.append(mean1)\n",
    "means.append(mean2)\n",
    "means.append(mean3)\n",
    "means.append(mean4)\n",
    "means.append(mean5)\n",
    "means=np.array(means)\n",
    "means=np.asmatrix(means)\n",
    "means=means.transpose()\n",
    "covmats=[]\n",
    "covmats.append(cov1)\n",
    "covmats.append(cov2)\n",
    "covmats.append(cov3)\n",
    "covmats.append(cov4)\n",
    "covmats.append(cov5)\n",
    "print(covmats)\n",
    "#test qda\n",
    "means=means.transpose()\n",
    "index=0\n",
    "index2=0\n",
    "pdf=0;\n",
    "classifier=0\n",
    "total_wrong_labels=0;\n",
    "ypred=[]\n",
    "while(index<ytest.size):\n",
    "    x_i=Xtest[index]\n",
    "    index2=0\n",
    "    classifier=0\n",
    "    pdf=0\n",
    "    while(index2<(means.size)/2):\n",
    "        class_mean=means[index2]\n",
    "        class_mean=np.array(class_mean)\n",
    "        class_mean=class_mean.flatten()\n",
    "        pdf_i=multivariate_normal.pdf(x_i, class_mean, covmats[index2])    \n",
    "        if(pdf_i>=pdf):\n",
    "            pdf=pdf_i\n",
    "            classifier=index2\n",
    "        index2=index2+1\n",
    "    label=classifier+1\n",
    "    if label != ytest[index]:\n",
    "        total_wrong_labels = total_wrong_labels+1\n",
    "    index=index+1\n",
    "    ypred.append(label)\n",
    "acc=(ytest.size-total_wrong_labels)/ytest.size\n",
    "ypred=np.array(ypred)\n",
    "ypred=np.asmatrix(ypred)\n",
    "ypred=ypred.transpose()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing least squares method to estimate w\n",
    "if sys.version_info.major == 2:\n",
    "    X,y,Xtest,ytest = pickle.load(open('diabetes.pickle','rb'))\n",
    "else:\n",
    "    X,y,Xtest,ytest = pickle.load(open('diabetes.pickle','rb'),encoding = 'latin1')\n",
    "\n",
    "X_i = np.concatenate((np.ones((X.shape[0],1)), X), axis=1)\n",
    "Xtest_i = np.concatenate((np.ones((Xtest.shape[0],1)), Xtest), axis=1)\n",
    "x=X_i\n",
    "x_t = x.transpose()\n",
    "first_step = np.matmul(x_t,x) # multiplying x transpose and x\n",
    "second_step = inv(first_step) # taking inverse of first step\n",
    "third_step = np.matmul(second_step,x_t) # multiplying second step and x transpose\n",
    "final_step = np.matmul(third_step,y) # multiplying third step and y(output of training dataset)\n",
    "w = final_step\n",
    "#print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (200,65) and (64,1) not aligned: 65 (dim 1) != 64 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-9616e34cf7ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mmse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfourth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmse\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mfind_mse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtest_i\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mytest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-9616e34cf7ef>\u001b[0m in \u001b[0;36mfind_mse\u001b[0;34m(input_var, y_var, w_est)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfind_mse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw_est\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mfirst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw_est\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0msecond\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubtract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mthird\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msecond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (200,65) and (64,1) not aligned: 65 (dim 1) != 64 (dim 0)"
     ]
    }
   ],
   "source": [
    "# using estimated w to predict \n",
    "# x_test = np.array(Xtest) # converting Xtest to array to be sure\n",
    "# y_test = np.array(ytest) # converting ytest to array to be sure\n",
    "X_i = np.concatenate((np.ones((X.shape[0],1)), X), axis=1)\n",
    "Xtest_i = np.concatenate((np.ones((Xtest.shape[0],1)), Xtest), axis=1)\n",
    "def find_mse(input_var,y_var,w_est):\n",
    "    N=y_var.size\n",
    "    first=np.matmul(input_var,w_est)\n",
    "    second=np.subtract(y_var,first)\n",
    "    third=second.transpose()\n",
    "    fourth=np.matmul(third,second)\n",
    "    mse=fourth/N\n",
    "    return mse    \n",
    "mse= find_mse(Xtest_i,ytest,w)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
